# compare_all.py
"""
One-stop portfolio optimiser:
  • PSO
  • Gradient Descent (+ transaction-cost penalty)
  • Genetic Algorithm  (new)
  • PPO  (pre-trained weights – reports/ppo_weights_real.csv)

Data   : data/historical_returns.csv  (generated by import_data.py)
Tickers: AAPL, MSFT, AMZN, NVDA, GOOGL, XOM, UNH, JNJ, V, BRK-B
Output : prints a tabulated summary of Return, Risk, Sharpe & runtime.
"""

import numpy as np
import pandas as pd
from time import time
from scipy.optimize import minimize
from tabulate import tabulate
from itertools import combinations
import matplotlib.pyplot as plt
import yfinance as yf
import os
import random

# ----------------------------
# 0 . LOAD DATA & CONSTANTS
# ----------------------------
TICKERS = ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'GOOGL',
           'XOM', 'UNH', 'JNJ', 'V', 'BRK-B']   # same list used by PPO loader
RF_RATE = 0.02                                  # risk-free rate for Sharpe
TRADING_DAYS = 252         # average number of trading days in a year
RF = 0.02                  # risk-free rate for Sharpe calculation
MAX_WEIGHT = 0.30
CARDINALITY = 5
START_DATE = '2013-01-01'
END_DATE = '2018-12-31'
np.random.seed(42)

def load_or_download_data():
    fname = "data/historical_returns.csv"
    if os.path.exists(fname):
        df = pd.read_csv(fname)
        df.columns = df.columns.str.strip().str.upper()
        df.index = pd.date_range(start="2013-01-01", periods=len(df), freq="B")
    else:
        print("Downloading from Yahoo Finance...")
        os.makedirs("data", exist_ok=True)
        end_date = (pd.to_datetime(END_DATE) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')
        prices = yf.download(TICKERS, start=START_DATE, end=end_date, progress=False)['Close']
        df = prices.pct_change().dropna()
        df.to_csv(fname)
    missing = [t for t in TICKERS if t not in df.columns]
    if missing:
        raise ValueError(f"Missing tickers in CSV: {missing}")
    return df[TICKERS]

returns = load_or_download_data()
ret_full = returns
exp_ret = returns.mean()             # monthly mean
cov_mat = returns.cov()
N_ASSETS = len(TICKERS)
all_combinations = list(combinations(range(N_ASSETS), CARDINALITY))

# helper
def perf(weights, mu=exp_ret, cov=cov_mat, rf=RF_RATE):
    ret = np.dot(weights, mu) * 12                     # annualise
    risk = np.sqrt(np.dot(weights.T, np.dot(cov*12, weights)))
    sharpe = (ret - rf) / risk
    return ret, risk, sharpe


# ----------------------------
# 1 . PARTICLE SWARM OPTIM
# ----------------------------
def initialize_swarm(n_particles, n_assets):
    swarm = []
    for _ in range(n_particles):
        w = np.random.rand(n_assets)
        w /= w.sum()
        v = np.random.rand(n_assets)*0.1
        swarm.append((w, v))
    return swarm

def enforce_constraints(weights):
    weights = np.clip(weights, 0, MAX_WEIGHT)
    zero_indices = np.argsort(weights)[:-CARDINALITY]
    weights[zero_indices] = 0

    total = weights.sum()
    if total <= 0:
        return np.ones_like(weights) / len(weights)
    weights = (weights / total) * (1 / (1 + 1e-8))
    return weights

def run_pso(mu, cov, n_particles=50, iters=3000,
            phi1=1.8, phi2=2.0, inertia=0.4):
    swarm = initialize_swarm(n_particles, len(mu))
    pbest_pos = [p[0].copy() for p in swarm]
    pbest_val = [perf(p[0], mu, cov)[2] for p in swarm]

    gbest_idx = int(np.argmax(pbest_val))
    gbest_pos = pbest_pos[gbest_idx].copy()
    gbest_val = pbest_val[gbest_idx]

    for _ in range(iters):
        for i in range(n_particles):
            w, v = swarm[i]
            r1, r2 = np.random.rand(), np.random.rand()
            cognitive = phi1*r1*(pbest_pos[i]-w)
            social    = phi2*r2*(gbest_pos-w)
            v_new = inertia*v + cognitive + social
            w_new = enforce_constraints(np.clip(w + v_new, 0, 1))

            _, _, s = perf(w_new, mu, cov)
            if s > pbest_val[i]:
                pbest_val[i], pbest_pos[i] = s, w_new.copy()
                if s > gbest_val:
                    gbest_val, gbest_pos = s, w_new.copy()

            swarm[i] = (w_new, v_new)
    return gbest_pos

# ----------------------------
# 2 . GRADIENT DESCENT 
# ----------------------------
def project_weights(w, min_weight=0.05, max_weight=1.0):
    constraints = [
        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
        {'type': 'ineq', 'fun': lambda x: x - min_weight}
    ]
    bounds = [(min_weight, max_weight)] * len(w)
    res = minimize(lambda x: np.linalg.norm(x - w), w, method='SLSQP', bounds=bounds, constraints=constraints)
    return res.x if res.success else np.clip(w, min_weight, max_weight) / np.clip(np.sum(w), 1e-6, None)

def gradient_with_costs(w, prev_w, mu, cov, alpha, lam=0.1, cost=0.001):
    return mu - 2*alpha*np.dot(cov, w) - 2*lam*w + 2*cost*(prev_w - w)

def improved_gd(mu, cov, alpha, w0, lam=0.1, cost=0.001, max_iter=1000):
    w = project_weights(w0)
    prev_w = w.copy()
    velocity = np.zeros_like(w)
    best_w = w.copy()
    best_obj = -np.inf
    lr = 1e-3
    decay = 0.99
    momentum = 0.98
    patience, max_patience = 0, 100

    for _ in range(max_iter):
        grad = gradient_with_costs(w, prev_w, mu, cov, alpha, lam, cost)
        obj = np.dot(w, mu) - alpha * np.dot(w.T, np.dot(cov, w)) - lam*np.sum(w**2) - cost*np.sum((w - prev_w)**2)
        if obj > best_obj + 1e-8:
            best_obj, best_w = obj, w.copy()
            patience = 0
        else:
            patience += 1
            if patience > max_patience: break
        velocity = momentum * velocity + lr * grad
        w += velocity
        w = project_weights(w)
        lr = max(1e-7, lr * decay)
        prev_w = w.copy()
    return best_w

# ----------------------------
# 3 . GENETIC ALGORITHM
# ----------------------------
def fitness(weights, mu=exp_ret, cov=cov_mat, rf=RF_RATE, alpha=0.9):
    """
    alpha = weight for Sharpe vs raw return (0: return only, 1: Sharpe only)
    """
    ann_return = np.dot(weights, mu) * 12
    ann_risk = np.sqrt(np.dot(weights.T, np.dot(cov * 12, weights)))
    sharpe = (ann_return - rf) / ann_risk
    return alpha * sharpe + (1 - alpha) * ann_return

def crossover_cardinality(p1, p2):
    """Uniform crossover keeping CARDINALITY constraint."""
    indices = list(set(np.nonzero(p1)[0]) | set(np.nonzero(p2)[0]))
    if len(indices) > CARDINALITY:
        indices = np.random.choice(indices, CARDINALITY, replace=False)
    weights = np.zeros_like(p1)
    weights[indices] = np.random.dirichlet(np.ones(len(indices)))
    return enforce_constraints(weights)

def mutate(weights, prob=0.2):
    if np.random.rand() > prob:
        return weights
    active = np.nonzero(weights)[0].tolist()
    inactive = list(set(range(N_ASSETS)) - set(active))
    if not inactive:
        return weights
    replace_out = np.random.choice(active)
    replace_in = np.random.choice(inactive)
    active.remove(replace_out)
    active.append(replace_in)
    new_weights = np.zeros_like(weights)
    new_weights[active] = np.random.dirichlet(np.ones(len(active)))
    return enforce_constraints(new_weights)

def ga_opt(mu, cov, pop=100, gens=1000, alpha=0.9):
    elite_size = int(0.05 * pop)
    λ_init, λ_final = 0.3, 1.0
    best_sharpe = -np.inf
    patience = 500
    tolerance = 0.005
    counter = 0
    early_stop_gen = None

    population = []
    for _ in range(pop):
        combo = all_combinations[np.random.choice(len(all_combinations))]
        weights = np.zeros(N_ASSETS)
        weights[list(combo)] = np.random.dirichlet(np.ones(CARDINALITY))
        population.append(weights)

    for gen in range(gens):
        λ = λ_init + (λ_final - λ_init) * (gen / (gens - 1))
        scored     = [(perf(w, mu, cov)[0] - λ*perf(w, mu, cov)[1], w)
                      for w in population]
        population = [w for _, w in sorted(scored, reverse=True)]
        elites     = population[:elite_size]

        children = []
        while len(children) < pop - elite_size:
            p1, p2 = random.sample(population[:50], 2)
            child  = crossover_cardinality(p1, p2)
            child  = mutate(child)
            children.append(child)
        population = elites + children

        if gen % 100 == 0:
            best = population[0]
            ret, risk, sharpe = perf(best)
            print(f"Gen {gen}: Return={ret:.2%}, Risk={risk:.2%}, Sharpe={sharpe:.2f}")

        # compute current best Sharpe
        current_sharpe = perf(population[0], mu, cov)[2]

        if current_sharpe > best_sharpe + tolerance:
            best_sharpe = current_sharpe
            counter = 0
        else:
            counter += 1

        if counter >= patience:
            print(f"Early stopping at generation {gen}: ")
            early_stop_gen = gen
            break

    return population[0]

# ----------------------------
# 4 . PPO – PRE-TRAINED LOAD
# ----------------------------
def load_ppo_performance():
    df = pd.read_csv("reports/ppo_weights_real.csv")
    avg_w = df.drop(columns="Time").mean().values
    total_ret, ann_ret, ann_risk, ann_sharpe = cumulative_stats(avg_w, ret_full)
    return avg_w, ann_ret, ann_risk, ann_sharpe

# ----------------------------
# 5. MASTER COMPARISON
# ----------------------------
def cumulative_stats(w, df):
    daily = df.values @ w
    total = np.prod(1 + daily) - 1
    ann_ret = daily.mean() * TRADING_DAYS
    ann_risk = daily.std(ddof=0) * np.sqrt(TRADING_DAYS)
    ann_sharpe = (ann_ret - RF_RATE) / ann_risk
    return total, ann_ret, ann_risk, ann_sharpe


def plot_comparison(rows):
    algos, rets, risks, sharpes = zip(*[(r[0], float(r[2].strip('%')), float(r[3].strip('%')), float(r[4])) for r in rows])
    fig, axs = plt.subplots(1, 3, figsize=(15, 4))
    axs[0].bar(algos, rets); axs[0].set_title("Avg Annual Return (%)")
    axs[1].bar(algos, risks); axs[1].set_title("Avg Annual Risk (%)")
    axs[2].bar(algos, sharpes); axs[2].set_title("Sharpe Ratio")
    for ax in axs: ax.set_xticklabels(algos, rotation=15); ax.set_ylabel("Value")
    plt.tight_layout(); os.makedirs("results", exist_ok=True)
    plt.savefig("results/comparison_summary.png")


def plot_equity_curves(labels, weights_list, test):
    fig, ax = plt.subplots(figsize=(10, 5))
    for label, w in zip(labels, weights_list):
        daily_returns = test.values @ w
        curve = np.cumprod(1 + daily_returns)
        curve *= 1000 / curve[0]
        ax.plot(curve, label=label)
    ax.set_title("Portfolio Growth (2017–2018)")
    ax.set_ylabel("Portfolio Value ($)")
    ax.set_xlabel("Days")
    ax.legend()
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f"${int(x):,}"))
    plt.tight_layout(); plt.savefig("results/equity_curves.png")

#def plot_single_curves(labels, weights_list, test):
#   for label, w in zip(labels, weights_list):
#       daily_returns = test.values @ w
#       curve = 1000 * np.cumprod(1 + daily_returns)
#       fig, ax = plt.subplots(figsize=(8, 4))
#       ax.plot(curve, label=label)
#       ax.set_title(f"{label} Portfolio Growth (2017–2018)")
#       ax.set_ylabel("Portfolio Value ($)")
#       ax.set_xlabel("Days")
#       ax.legend()
#       ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f"${int(x):,}"))
#       fname = label.lower().replace(" ", "_") + "_curve.png"
#       plt.tight_layout(); plt.savefig(f"results/{fname}")

# ----------------------------
# Run All
# ----------------------------
def compare_all():
    train = returns.loc["2013-01-01":"2016-12-30"]
    test  = returns.loc["2017-01-01":"2018-12-31"]
    mu, cov = train.mean(), train.cov()
    rows, weights = [], []

    algos = [
        ("PSO", lambda: run_pso(mu, cov)),
        ("Gradient Descent", lambda: improved_gd(mu.values, cov.values, alpha=1.0, w0=np.random.dirichlet(np.ones(N_ASSETS)))),
        ("Genetic Algorithm", lambda: ga_opt(mu, cov)),
        ("PPO (pre-trained)", load_ppo_performance)
    ]

    for name, fn in algos:
        t0 = time()
        if name.startswith("PPO"):
            w, ann_ret, ann_risk, ann_sharpe = fn()
            total_ret, ann_ret, ann_risk, ann_sharpe = cumulative_stats(w, test)
            dur = 0

        else:
            w = fn()
            total_ret, ann_ret, ann_risk, ann_sharpe = cumulative_stats(w, test)
            dur = time() - t0
        weights.append(w)
        rows.append([name, f"{total_ret:.2%}", f"{ann_ret:.2%}", f"{ann_risk:.2%}", f"{ann_sharpe:.2f}", f"{dur:.1f}"])

    print(tabulate(rows, headers=["Algo", "Return 2 y", "Avg Annual Return", "Avg Annual Risk", "Sharpe", "Time (s)"], tablefmt="grid"))
    plot_comparison(rows)
    plot_equity_curves([r[0] for r in rows], weights, test)
#   plot_single_curves([r[0] for r in rows], weights, test)


# ----------------------------
if __name__ == "__main__":
    compare_all()
